{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第三题：实现带有拉普拉斯修正的朴素贝叶斯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实验内容：\n",
    "1. 叙述拉普拉斯修正的作用\n",
    "2. 给出使用的数据集\n",
    "3. 给出实现的代码，要有详细的注释\n",
    "4. 给出模型评价指标的结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import numpy as np\n",
    "spambase = np.loadtxt('data/spambase/spambase.data', delimiter = \",\")\n",
    "spamx = spambase[:, :57]\n",
    "spamy = spambase[:, 57]\n",
    "from sklearn.model_selection import train_test_split\n",
    "trainX, testX, trainY, testY = train_test_split(spamx, spamy, test_size = 0.4, random_state = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "class myGaussianNB:\n",
    "    '''\n",
    "    处理连续特征的带拉普拉斯修正的高斯朴素贝叶斯\n",
    "    '''\n",
    "    def __init__(self, alpha=1.0):\n",
    "        '''\n",
    "        初始化四个字典\n",
    "        self.label_mapping     类标记 与 下标(int)\n",
    "        self.probability_of_y  类标记 与 先验概率(float)\n",
    "        self.mean              类标记 与 均值(np.ndarray)\n",
    "        self.var               类标记 与 方差(np.ndarray)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha: float, 拉普拉斯平滑的参数\n",
    "        '''\n",
    "        self.label_mapping = dict()\n",
    "        self.probability_of_y = dict()\n",
    "        self.mean = dict()\n",
    "        self.var = dict()\n",
    "        self.alpha = alpha  # 拉普拉斯平滑的参数\n",
    "        \n",
    "    def _clear(self):\n",
    "        '''\n",
    "        为了防止一个实例反复的调用fit方法，我们需要每次调用fit前，将之前学习到的参数删除掉\n",
    "        '''\n",
    "        self.label_mapping.clear()\n",
    "        self.probability_of_y.clear()\n",
    "        self.mean.clear()\n",
    "        self.var.clear()\n",
    "    \n",
    "    def fit(self, trainX, trainY):\n",
    "        '''\n",
    "        这里，我们要根据trainY内的类标记，针对每类，计算这类的先验概率，以及这类训练样本每个特征的均值和方差\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            trainX: np.ndarray, 训练样本的特征, 维度：(样本数, 特征数)\n",
    "        \n",
    "            trainY: np.ndarray, 训练样本的标记, 维度：(样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 先调用_clear\n",
    "        self._clear()\n",
    "        \n",
    "        # 获取类标记\n",
    "        labels = np.unique(trainY)\n",
    "        \n",
    "        # 添加类标记与下标的映射关系\n",
    "        self.label_mapping = {label: index for index, label in enumerate(labels)}\n",
    "        \n",
    "        # 遍历每个类\n",
    "        for label in labels:\n",
    "            \n",
    "            # 取出为label这类的所有训练样本，存为 x\n",
    "            x = trainX[trainY == label, :]\n",
    "            \n",
    "            # 计算先验概率，用 x 的样本个数除以训练样本总个数，存储到 self.probability_of_y 中，键为 label，值为先验概率\n",
    "            self.probability_of_y[label] = (x.shape[0] + self.alpha) / (trainX.shape[0] + len(labels) * self.alpha)\n",
    "            \n",
    "            # 对 x 的每列求均值，使用 keepdims = True 保持维度，存储到 self.mean 中，键为 label，值为每列的均值组成的一个二维 np.ndarray\n",
    "            self.mean[label] = np.mean(x, axis=0, keepdims=True)\n",
    "            \n",
    "            # 这句话是debug用的，如果不满足下面的条件，会直接跳出\n",
    "            assert self.mean[label].shape == (1, trainX.shape[1])\n",
    "            \n",
    "            # 对 x 的每列求方差，使用 keepdims = True 保持维度，存储到 self.var 中，键为 label，值为每列的方差组成的一个二维 np.ndarray\n",
    "            self.var[label] = np.var(x, axis=0, keepdims=True)\n",
    "            \n",
    "            # debug\n",
    "            assert self.var[label].shape == (1, trainX.shape[1])\n",
    "            \n",
    "            # 平滑，因为方差在公式的分母部分，我们要加一个很小的数，防止除以0\n",
    "            self.var[label] += self.alpha\n",
    "        \n",
    "    def predict(self, testX):\n",
    "        '''\n",
    "        给定测试样本，预测测试样本的类标记，这里我们要实现化简后的公式\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            testX: np.ndarray, 测试的特征, 维度：(测试样本数, 特征数)\n",
    "    \n",
    "        Returns\n",
    "        ----------\n",
    "            prediction: np.ndarray, 预测结果, 维度：(测试样本数, )\n",
    "        '''\n",
    "        \n",
    "        # 初始化一个空矩阵 results，存储每个样本属于每个类的概率，维度是 (测试样本数，类别数)，每行表示一个样本，每列表示一个特征\n",
    "        results = np.empty((testX.shape[0], len(self.probability_of_y)))\n",
    "        \n",
    "        # 初始化一个列表 labels，按 self.label_mapping 的映射关系存储所有的标记，一会儿会在下面的循环内部完成存储\n",
    "        labels = [0] * len(self.probability_of_y)\n",
    "        \n",
    "        # 遍历当前的类，label为类标记，index为下标，我们将每个样本预测出来的这个 label 的概率，存到 results 中的第 index 列\n",
    "        for label, index in self.label_mapping.items():\n",
    "            \n",
    "            # 先验概率存为 py\n",
    "            py = self.probability_of_y[label]\n",
    "            \n",
    "            # 使用变换后的公式，计算所有特征的条件概率之和，存为sum_of_conditional_probability\n",
    "            sum_of_conditional_probability = np.sum(-0.5 * np.log(2 * np.pi * self.var[label]) - 0.5 * ((testX - self.mean[label]) / self.var[label]) ** 2, axis=1)\n",
    "            \n",
    "            # 使用变换后的公式，将 条件概率 与 log先验概率 相加，存为result，维度应该是 (测试样本数, )\n",
    "            result = sum_of_conditional_probability + np.log(py)\n",
    "            \n",
    "            # 将所有测试样本属于当前这类的概率，存入到results中\n",
    "            results[:, index] = result\n",
    "            \n",
    "            # 将当前的label，按index顺序放入到labels中\n",
    "            labels[index] = label\n",
    "        \n",
    "        # 将labels转换为np.ndarray\n",
    "        np_labels = np.array(labels)\n",
    "        \n",
    "        # 循环结束后，就计算出了给定测试样本，当前样本属于这类的概率的近似值，存放在了results中，每行对应一个样本，每列对应一个特征\n",
    "        # 我们要求每行的最大值对应的下标，也就是求每个样本，概率值最大的那个下标是什么，结果存入max_prob_index中\n",
    "        max_prob_index = np.argmax(results, axis=1)\n",
    "        \n",
    "        # 现在得到了每个样本最大概率对应的下标，我们需要把这个下标变成 np_labels 中的标记\n",
    "        prediction = np_labels[max_prob_index]\n",
    "        \n",
    "        # 返回预测结果\n",
    "        return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7246\n",
      "Precision: 0.8868\n",
      "Recall: 0.3301\n",
      "F1 Score: 0.4811\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# 假设 model 是通过 myGaussianNB 训练好的模型\n",
    "model = myGaussianNB()\n",
    "model.fit(trainX, trainY)\n",
    "\n",
    "# 假设 testX 和 testY 是测试集\n",
    "predicted_labels = model.predict(testX)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(testY, predicted_labels)\n",
    "# 计算查准率\n",
    "precision = precision_score(testY, predicted_labels, average='binary')  \n",
    "# 计算查全率\n",
    "recall = recall_score(testY, predicted_labels, average='binary')  \n",
    "# 计算 F1 值\n",
    "f1 = f1_score(testY, predicted_labels, average='binary')  \n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
